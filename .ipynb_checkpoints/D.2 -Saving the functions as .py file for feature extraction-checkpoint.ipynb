{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import time\n",
    "from time import strftime\n",
    "from datetime import datetime\n",
    "import matplotlib \n",
    "from IPython.core.display import clear_output\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "import re\n",
    "#import nlkt\n",
    "\n",
    "import nltk\n",
    "\n",
    "from nltk import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "#from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "stopWords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parser(html):\n",
    "    \n",
    "    ### returns the parser given a raw html \n",
    "    \n",
    "    x=BeautifulSoup(html.text,\"html.parser\")\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 885,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_of_videos(parser,box):\n",
    "    \n",
    "    ### returns the number of videos for the different boxes\n",
    "    ### This also checks for youtube videos  -- that are linked different in Kickstarter [NOT IN MVP]\n",
    "    \n",
    "    if box==\"about\":\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            # Normal video\n",
    "            a=len(parser.find('div',class_='full-description js-full-description responsive' + '-media formatted-lists'\n",
    "            ).find_all('div', class_=\"video-player\"))\n",
    "\n",
    "            # YouTube Video\n",
    "            #b=len(parser.find('div',class_='full-description js-full-description responsive' + '-media formatted-lists'\n",
    "            #).find_all('div', class_=\"video-player\"))\n",
    "        \n",
    "        except AttributeError:\n",
    "            \n",
    "            a=np.nan\n",
    "        \n",
    "        \n",
    "        \n",
    "        return a\n",
    "    \n",
    "    elif box==\"risk\":\n",
    "        try:\n",
    "            b= len(parser.find('div',class_='mb3 mb10-sm mb3 js-risks'\n",
    "            ).find_all('div', class_=\"video-player\"))\n",
    "        except AttributeError:\n",
    "            b=np.nan\n",
    "            \n",
    "        return b   \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 886,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_of_pics(parser,box):\n",
    "    \n",
    "    ### returns the number of videos for the different boxes\n",
    "    \n",
    "    if box==\"about\":\n",
    "        try:\n",
    "            a= len(parser.find(\n",
    "                'div',\n",
    "                class_='full-description js-full-description responsive-media formatted-lists'\n",
    "            ).find_all('img'))\n",
    "    \n",
    "        except AttributeError:\n",
    "            \n",
    "            a=np.nan\n",
    "        \n",
    "        return a\n",
    "    \n",
    "    \n",
    "    elif box==\"risk\":\n",
    "        try:\n",
    "            \n",
    "            b=len(parser.find('div',class_='mb3 mb10-sm mb3 js-risks'\n",
    "                ).find_all('img'))\n",
    "            \n",
    "            \n",
    "        except AttributeError:\n",
    "            b=np.nan\n",
    "            \n",
    "        return b    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_pitch_video(parser):\n",
    "    \n",
    "    ### returns True is the pitching pic is a video and returns false otherwise\n",
    "    \n",
    "    obj=parser.find(\n",
    "            'div',\n",
    "            class_='mx-4 mx-12-md mx0-lg'\n",
    "        ).find_all('div', class_=\"aspect-ratio aspect-ratio--16x9 w100p ksr-video-player bg-black\")\n",
    "    \n",
    "    if len(obj)>=1:\n",
    "        return True\n",
    "    \n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 896,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_of_perks(parser):\n",
    "     \n",
    "    ### returns the number of perks for a given campaing\n",
    "    \n",
    "    #This are the available perks\n",
    "    \n",
    "    try:\n",
    "        perk=parser.find(\n",
    "                    'div',\n",
    "                    class_=\"NS_projects__rewards_list js-project-rewards\"\n",
    "                )\n",
    "\n",
    "        perk_UF=perk.find_all(\"li\",class_=\"hover-group pledge--inactive pledge-selectable-sidebar\")\n",
    "\n",
    "            \n",
    "    # this is usefull for campaings that are already founded or unfounded\n",
    "        if len(perk_UF) != 0:\n",
    "\n",
    "            return len(perk_UF)\n",
    "        # this is usefull for live campaings\n",
    "\n",
    "        else:\n",
    "\n",
    "            a=len(perk.find_all('li',class_=\"hover-group js-reward-available pledge--available pledge-selectable-sidebar\"))\n",
    "\n",
    "            # This are the perks that are gone -- For the MVP I will put them together but they might be \n",
    "\n",
    "            b=len(perk.find_all('li',class_=\"hover-group pledge--all-gone pledge-selectable-sidebar\"))\n",
    "\n",
    "            return a+b\n",
    "    \n",
    "    except AttributeError:\n",
    "        \n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def price_in_perks(parser):\n",
    "    \n",
    "    ### Returns an array of the amount asked for each perk in order of appearence\n",
    "    \n",
    "    # For available perks\n",
    "    per=parser.find(\n",
    "            'div',\n",
    "            class_=\"NS_projects__rewards_list js-project-rewards\"\n",
    "        ).find_all('li',class_=\"hover-group js-reward-available pledge--available pledge-selectable-sidebar\")\n",
    "    \n",
    "    l=[]\n",
    "    for i in range(len(per)):\n",
    "\n",
    "        r=per[i].find_all(\"span\",class_=\"money\")[0].text\n",
    "    \n",
    "        r=r.replace(\",\",\"\")\n",
    "        r=r.replace(\".\",\"\")\n",
    "        \n",
    "        l.append([int(''.join(i)) for is_digit, i in groupby(r, str.isdigit) if is_digit][0])\n",
    "   \n",
    "    l=np.array(l)\n",
    "    \n",
    "    # For unavilable perks\n",
    "    \n",
    "    per1=parser.find(\n",
    "            'div',\n",
    "            class_=\"NS_projects__rewards_list js-project-rewards\"\n",
    "        ).find_all('li',class_=\"hover-group pledge--all-gone pledge-selectable-sidebar\")\n",
    "    \n",
    "    if len(per1)==1:\n",
    "        return l\n",
    "    else:\n",
    "        l1=[]\n",
    "        for i in range(len(per)):\n",
    "\n",
    "            r=per1[i].find_all(\"span\",class_=\"money\")[0].text\n",
    "    \n",
    "            r=r.replace(\",\",\"\")\n",
    "            r=r.replace(\".\",\"\")\n",
    "        \n",
    "            l1.append([int(''.join(i)) for is_digit, i in groupby(r, str.isdigit) if is_digit][0])\n",
    "   \n",
    "        l1=np.array(l1)\n",
    "     \n",
    "        return np.concatenate((l,l1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 874,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(parser,box):\n",
    "    \n",
    "    ### Gets the text for a given box in the campaing.\n",
    "    ### this will only clean basic html feature, remove bold, italic, etc\n",
    "    ### it will keep the raw text\n",
    "    \n",
    "    if box==\"about\":\n",
    "        \n",
    "        try:\n",
    "            text=parser.find(\n",
    "                'div',\n",
    "                class_='full-description js-full-description responsive-media formatted-lists'\n",
    "            ).get_text(' ')\n",
    "\n",
    "            text=\" \".join(text.split()).strip()\n",
    "            \n",
    "        except AttributeError:  \n",
    "            \n",
    "            text='NA'\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    elif box==\"risk\":\n",
    "        \n",
    "        try:\n",
    "            text=parser.find(\n",
    "                'div',\n",
    "                class_='mb3 mb10-sm mb3 js-risks'\n",
    "            ).get_text(' ')\n",
    "\n",
    "            text=\" \".join(text.split()).strip()\n",
    "            \n",
    "        except AttributeError:  \n",
    "            \n",
    "            text='NA'\n",
    "        \n",
    "        return text.strip(\"Risks and challenges\").strip(\"Learn about accountability on Kickstarter\")\n",
    "    \n",
    "    elif box==\"perks\":\n",
    "        \n",
    "        try:\n",
    "            perk=parser.find(\n",
    "                    'div',\n",
    "                    class_=\"NS_projects__rewards_list js-project-rewards\"\n",
    "                )\n",
    "\n",
    "            perk_UF=perk.find_all(\"li\",class_=\"hover-group pledge--inactive pledge-selectable-sidebar\")\n",
    "            \n",
    "        \n",
    "        except AttributeError:\n",
    "            \n",
    "            tp=\"NA\"\n",
    "            return tp\n",
    "            \n",
    "\n",
    "        # this is usefull for campaings that are already founded or unfounded\n",
    "        if len(perk_UF) != 0:\n",
    "\n",
    "            try:\n",
    "\n",
    "                tp=''\n",
    "\n",
    "                for i in range(len(perk_UF)):\n",
    "                    neetp=perk_UF[i].find_all(\n",
    "                        \"div\",class_='pledge__reward-description pledge__reward-description--expanded')[0].get_text(' ')\n",
    "                    tp=tp + neetp\n",
    "\n",
    "                tp=\" \".join(tp.split()).strip() \n",
    "\n",
    "            except AttributeError:  \n",
    "\n",
    "                tp='NA'   \n",
    "\n",
    "                return tp   \n",
    "\n",
    "        else:\n",
    "\n",
    "            try:\n",
    "                a=perk.find_all('li',\n",
    "                                class_=\"hover-group js-reward-available pledge--available pledge-selectable-sidebar\")\n",
    "\n",
    "                # This are the perks that are gone -- For the MVP I will put them together but they might be \n",
    "\n",
    "                b=perk.find_all('li',class_=\"hover-group pledge--all-gone pledge-selectable-sidebar\")\n",
    "\n",
    "            except AttributeError: \n",
    "\n",
    "                tp=\"NA\"\n",
    "\n",
    "                return tp\n",
    "\n",
    "            try:\n",
    "\n",
    "                tp=''\n",
    "                for i in range(len(a)):\n",
    "                    neetp=a[i].find_all(\n",
    "                        \"div\",class_='pledge__reward-description pledge__reward-description--expanded')[0].get_text(' ')\n",
    "                    tp=tp + neetp\n",
    "\n",
    "                for i in range(len(b)):\n",
    "                    neetp=b[i].find_all(\n",
    "                        \"div\",class_='pledge__reward-description pledge__reward-description--expanded')[0].get_text(' ')\n",
    "                    tp=tp + neetp\n",
    "\n",
    "                tp=\" \".join(tp.split()).strip() \n",
    "\n",
    "            except AttributeError:  \n",
    "\n",
    "                tp='NA'   \n",
    "                return tp\n",
    "        \n",
    "            \n",
    "        return tp   \n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_of_sentences(text):\n",
    "    if text==\"NA\":\n",
    "        return np.nan\n",
    "    else:\n",
    "    \n",
    "        sentences = sent_tokenize(text)\n",
    "\n",
    "        return len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_of_words(text):\n",
    "    \n",
    "    if text==\"NA\":\n",
    "        \n",
    "        return np.nan\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        tokens = word_tokenize(text)\n",
    "\n",
    "        #this removes all characters that are not words\n",
    "        words = [word.lower() for word in tokens if word.isalpha()]\n",
    "\n",
    "        return len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_of_links(parser,box):\n",
    "    \n",
    "    if box == 'about':\n",
    "        try:\n",
    "            return len(parser.find(\n",
    "                'div',\n",
    "                class_='full-description js-full-description responsive-media formatted-lists'\n",
    "            ).find_all('a'))\n",
    "        except AttributeError:  \n",
    "            \n",
    "            return np.nan\n",
    "            \n",
    "           \n",
    "    elif box == 'risk':\n",
    "        try:\n",
    "            return len(parser.find(\n",
    "                'div',\n",
    "                class_='mb3 mb10-sm mb3 js-risks'\n",
    "            ).find_all('a'))-1\n",
    "        except AttributeError:  \n",
    "            \n",
    "            return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_of_bold(parser,box):\n",
    "    \n",
    "    '''returns #bold_words/#total_words for boxes \"about\" and \" risks\" ''' \n",
    "    \n",
    "    if box==\"about\":\n",
    "        \n",
    "        text= get_text(parser,box)\n",
    "        \n",
    "        if text == \"NA\":\n",
    "            \n",
    "            return np.nan\n",
    "        \n",
    "        else:\n",
    "        \n",
    "            bold =parser.find(\n",
    "                'div',\n",
    "                class_='full-description js-full-description responsive-media formatted-lists'\n",
    "            ).find_all(\"b\")\n",
    "\n",
    "            words=\" \".join([sentence.get_text() for sentence in bold]).strip()\n",
    "\n",
    "            words = word_tokenize(words)\n",
    "\n",
    "            words=[word.lower() for word in words if word.isalpha()]\n",
    "            \n",
    "            if num_of_words(text)==0:\n",
    "                frequency=0\n",
    "            else:\n",
    "                frequency=len(words)/num_of_words(text)\n",
    "            \n",
    "            return frequency*100\n",
    "        \n",
    "    \n",
    "    elif box == \"risk\":\n",
    "        \n",
    "        text= get_text(parser,box)\n",
    "        \n",
    "        if text == \"NA\":\n",
    "            \n",
    "            return np.nan\n",
    "        \n",
    "        else:\n",
    "        \n",
    "            bold=parser.find(\n",
    "                'div',\n",
    "                class_='mb3 mb10-sm mb3 js-risks'\n",
    "            ).find_all(\"b\")\n",
    "\n",
    "            words=\" \".join([sentence.get_text() for sentence in bold]).strip()\n",
    "\n",
    "            words = word_tokenize(words)\n",
    "\n",
    "            words=[word.lower() for word in words if word.isalpha()]\n",
    "            \n",
    "            if num_of_words(text)==0:\n",
    "                frequency=0\n",
    "            else:\n",
    "                frequency=len(words)/num_of_words(text)\n",
    "            \n",
    "            return frequency*100\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_of_italic(parser,box):\n",
    "    \n",
    "    '''returns #bold_words/#total_words for boxes \"about\" and \" risks\" ''' \n",
    "    \n",
    "    if box==\"about\":\n",
    "        \n",
    "        text= get_text(parser,box)\n",
    "        \n",
    "        if text == \"NA\":\n",
    "            \n",
    "            return np.nan\n",
    "        \n",
    "        else:\n",
    "        \n",
    "            bold =parser.find(\n",
    "                'div',\n",
    "                class_='full-description js-full-description responsive-media formatted-lists'\n",
    "            ).find_all(\"i\")\n",
    "\n",
    "            words=\" \".join([sentence.get_text() for sentence in bold]).strip()\n",
    "\n",
    "            words = word_tokenize(words)\n",
    "\n",
    "            words=[word.lower() for word in words if word.isalpha()]\n",
    "            \n",
    "            if num_of_words(text)==0:\n",
    "                frequency=0\n",
    "            else:\n",
    "                frequency=len(words)/num_of_words(text)\n",
    "            \n",
    "            \n",
    "            return frequency*100\n",
    "        \n",
    "    \n",
    "    elif box == \"risk\":\n",
    "        \n",
    "        text= get_text(parser,box)\n",
    "        \n",
    "        if text == \"NA\":\n",
    "            \n",
    "            return np.nan\n",
    "        \n",
    "        else:\n",
    "        \n",
    "            bold=parser.find(\n",
    "                'div',\n",
    "                class_='mb3 mb10-sm mb3 js-risks'\n",
    "            ).find_all(\"i\")\n",
    "\n",
    "            words=\" \".join([sentence.get_text() for sentence in bold]).strip()\n",
    "\n",
    "            words = word_tokenize(words)\n",
    "\n",
    "            words=[word.lower() for word in words if word.isalpha()]\n",
    "            \n",
    "            if num_of_words(text)==0:\n",
    "                frequency=0\n",
    "            else:\n",
    "                frequency=len(words)/num_of_words(text)\n",
    "            \n",
    "            return frequency*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_of_exclamation(parser,box):\n",
    "    \n",
    "    text= get_text(parser,box)\n",
    "    \n",
    "    if text == \"NA\":\n",
    "        \n",
    "        exclamation_num=np.nan\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        words = word_tokenize(text)\n",
    "        \n",
    "        exclamation_num=words.count(\"!\")\n",
    "    \n",
    "    return exclamation_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 782,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From https://blog.hubspot.com/sales/sensory-words-to-spice-up-your-sales-pitch\n",
    "\n",
    "Pitch_words=\"see picture appear outlook focus observe notice \\\n",
    "watch overview sound hear mention inquire tune listen vocal remark say \\\n",
    "report feel grasp firm pressure grip flow warm emotional active assume you value \\\n",
    "and or imagine remember results easy benefit improved solution proven thank because welcome \\\n",
    "free new first premium help save now safe better bargain instant powerful best risk sale tips\"\n",
    "\n",
    "Pitch_words=Pitch_words.split()\n",
    "\n",
    "def freq_of_stopwords(parser,box):\n",
    "    \n",
    "    ### retruns #stop_words/#words for a given campaing in a given section\n",
    "    \n",
    "    text=get_text(parser,box)\n",
    "    \n",
    "    \n",
    "    if text == \"NA\":\n",
    "        \n",
    "        freq=np.nan\n",
    "\n",
    "    elif num_of_words(text)==0:\n",
    "\n",
    "        freq=0.\n",
    "\n",
    "        \n",
    "\n",
    "    elif num_of_words(text)!=0:\n",
    "        \n",
    "        \n",
    "        \n",
    "        tokens = word_tokenize(text)\n",
    "\n",
    "        #this removes all characters that are not words\n",
    "        words = [word.lower() for word in tokens if word.isalpha()]\n",
    "\n",
    "        freq=(len([w for w in words if w in stopWords])/len(words))*100\n",
    "    \n",
    "    \n",
    "    return freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_of_pitchwords(parser,box):\n",
    "    \n",
    "    ### retruns #stop_words/#words for a given campaing in a given section\n",
    "    \n",
    "    text= get_text(parser,box)\n",
    "    \n",
    "    if text == \"NA\":\n",
    "        \n",
    "        freq=np.nan\n",
    "        \n",
    "    elif num_of_words(text)==0:\n",
    "\n",
    "        freq=0.    \n",
    "        \n",
    "    else:\n",
    "        \n",
    "        tokens = word_tokenize(text)\n",
    "\n",
    "        #this removes all characters that are not words\n",
    "        words = [word.lower() for word in tokens if word.isalpha()]\n",
    "\n",
    "        freq=(len([w for w in words if w in Pitch_words])/len(words))*100\n",
    "        \n",
    "    return freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_goal(par):\n",
    "    \n",
    "    ## returns the value of the goal for a ginve campaing \n",
    "    \n",
    "    mon=par.find_all(\"span\",class_=\"ksr-green-700\")[0].text\n",
    "\n",
    "    return int(''.join(c for c in mon if c.isdigit()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(url):\n",
    "    \n",
    "    ### Returns the given features for a given url of the campaing\n",
    "    \n",
    "    \n",
    "    new_features=[\"goal\",\"code\",\"num_videos\",\"num_pics\",\"num_perks\",\"num_links\",\n",
    "              \"num_of_sent_about\",\"num_of_sent_risk\",\"num_of_sent_perks\",\n",
    "             \"num_of_words_about\",\"num_of_words_risk\",\"num_of_words_perks\",              \n",
    "             \"freq_bold_A\",\n",
    "             \"freq_italic_A\",\n",
    "             \"num_of_exclamation_A\",\"num_of_exclamation_R\",\"num_of_exclamation_P\",\n",
    "             \"bool_A\",\"bool_P\",\n",
    "             \"freq_pitch_A\",\"freq_pitch_R\",\"freq_pitch_P\"]\n",
    "    \n",
    "    df_features=pd.DataFrame(columns=new_features)\n",
    "\n",
    "    \n",
    "    HTML= requests.get(url)\n",
    "    \n",
    "    \n",
    "    par=get_parser(HTML)\n",
    "    \n",
    "    goal = get_goal(par)\n",
    "    \n",
    "    text_about=get_text(par,\"about\")\n",
    "    text_risk=get_text(par,\"risk\")\n",
    "    text_perks=get_text(par,\"perks\")\n",
    "    \n",
    "    bA=1\n",
    "    \n",
    "    bP=1\n",
    "    \n",
    "    code=1\n",
    "    \n",
    "    if text_about==\"NA\":\n",
    "        bA=0\n",
    "    \n",
    "    if text_perks==\"NA\":\n",
    "        bP=0\n",
    "        \n",
    "    features=(goal,code,num_of_videos(par,\"about\"),num_of_pics(par,\"about\"),num_of_perks(par),num_of_links(par,\"about\"),\n",
    "              num_of_sentences(text_about), num_of_sentences(text_risk),num_of_sentences(text_perks),\n",
    "              num_of_words(text_about),num_of_words(text_risk),num_of_words(text_perks),\n",
    "              freq_of_bold(par,\"about\"),\n",
    "              freq_of_italic(par,\"about\"),\n",
    "              num_of_exclamation(par,\"about\"),num_of_exclamation(par,\"risk\"),num_of_exclamation(par,\"perks\"),\n",
    "              bA,bP,\n",
    "              freq_of_pitchwords(par,\"about\"),freq_of_pitchwords(par,\"risk\"),freq_of_pitchwords(par,\"perks\"))\n",
    "    \n",
    "    df_features.loc[0]=features\n",
    "    \n",
    "    return df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features=[\"goal\",\"code\",\"num_videos\",\"num_pics\",\"num_perks\",\"num_links\",\n",
    "              \"num_of_sent_about\",\"num_of_sent_risk\",\"num_of_sent_perks\",\n",
    "             \"num_of_words_about\",\"num_of_words_risk\",\"num_of_words_perks\",              \n",
    "             \"freq_bold_A\",\n",
    "             \"freq_italic_A\",\n",
    "             \"num_of_exclamation_A\",\"num_of_exclamation_R\",\"num_of_exclamation_P\",\n",
    "             \"bool_A\",\"bool_P\",\n",
    "             \"freq_pitch_A\",\"freq_pitch_R\",\"freq_pitch_P\"]\n",
    "    \n",
    "df_features=pd.DataFrame(columns=new_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 912,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bin_start: 49000;Request: 39999; Row ID: 39999; Frequency: 1.6190164226414536 requests/sec\n",
      "\n",
      "Run time: 311.73411297798157\n",
      "Average rate: 3.2078619514786055\n",
      "# of projects scraped: 1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/Users/natacha/Documents/Insight/Final Features/Final_Features_39000-39999.pkl']"
      ]
     },
     "execution_count": 912,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_on = time.time()\n",
    "    \n",
    "request_count = 0\n",
    "\n",
    "star_ID = 39000\n",
    "fin_ID = 40000\n",
    "\n",
    "scraped = joblib.load('/Users/natacha/Documents/Insight/Scraped_HTML/scraped_html_{}-{}.pkl'.format(\n",
    "        star_ID,\n",
    "        fin_ID - 1))\n",
    "\n",
    "\n",
    "new_features=[\"index1\",\"num_videos\",\"num_pics\",\"num_perks\",\"num_links\",\n",
    "          \"num_of_sent_about\",\"num_of_sent_risk\",\"num_of_sent_perks\",\n",
    "         \"num_of_words_about\",\"num_of_words_risk\",\"num_of_words_perks\",              \n",
    "         \"freq_bold_A\",\"freq_bold_R\",\n",
    "         \"freq_italic_A\",\"freq_italic_R\",\n",
    "         \"num_of_exclamation_A\",\"num_of_exclamation_R\",\"num_of_exclamation_P\",\n",
    "         \"bool_A\",\"bool_P\",\"bool_R\",\n",
    "         \"freq_pitch_A\",\"freq_pitch_R\",\"freq_pitch_P\"]\n",
    "\n",
    "\n",
    "df_features=pd.DataFrame(columns=new_features)\n",
    "\n",
    "\n",
    "for index, row in scraped.iterrows():\n",
    "\n",
    "    par=get_parser(row[\"HTML\"])\n",
    "\n",
    "    text_about=get_text(par,\"about\")\n",
    "    text_risk=get_text(par,\"risk\")\n",
    "    text_perks=get_text(par,\"perks\")\n",
    "\n",
    "    bA=1\n",
    "    bR=1\n",
    "    bP=1\n",
    "    if text_about==\"NA\":\n",
    "        bA=0\n",
    "    if text_risk==\"NA\":\n",
    "        bR=0\n",
    "    if text_perks==\"NA\":\n",
    "        bP=0\n",
    "\n",
    "    features=(row[\"index1\"],num_of_videos(par,\"about\"),num_of_pics(par,\"about\"),num_of_perks(par),num_of_links(par,\"about\"),\n",
    "              num_of_sentences(text_about), num_of_sentences(text_risk),num_of_sentences(text_perks),\n",
    "              num_of_words(text_about),num_of_words(text_risk),num_of_words(text_perks),\n",
    "              freq_of_bold(par,\"about\"),freq_of_bold(par,\"risk\"),\n",
    "              freq_of_italic(par,\"about\"),freq_of_italic(par,\"risk\"),\n",
    "              num_of_exclamation(par,\"about\"),num_of_exclamation(par,\"risk\"),num_of_exclamation(par,\"perks\"),\n",
    "              bA,bP,bR,\n",
    "              freq_of_pitchwords(par,\"about\"),freq_of_pitchwords(par,\"risk\"),freq_of_pitchwords(par,\"perks\")\n",
    "              )\n",
    "\n",
    "    #print(features)\n",
    "    #print(features)\n",
    "    #elapsed_time = time.time() - time_on\n",
    "    #print(index, end=\" \")\n",
    "\n",
    "    df_features.loc[index]=features\n",
    "\n",
    "    elapsed_time = time.time() - time_on\n",
    "    clear_output(wait = True)\n",
    "    print(\n",
    "            'Bin_start: {};Request: {}; Row ID: {}; Frequency: {} requests/sec'.format(bins[i],\n",
    "                request_count + star_ID,\n",
    "                index,\n",
    "                (request_count + 1) / elapsed_time\n",
    "            )\n",
    "        )\n",
    "    request_count += 1\n",
    "\n",
    "\n",
    "\n",
    "print()\n",
    "print('Run time:', run_time)\n",
    "print('Average rate:', len(scraped) / run_time)\n",
    "print('# of projects scraped:', len(scraped))\n",
    "\n",
    "features_final=pd.concat([meta_sample[star_ID:fin_ID], df_features],axis=1,join_axes=[meta_sample[star_ID:fin_ID].index])\n",
    "\n",
    "joblib.dump(\n",
    "features_final, '/Users/natacha/Documents/Insight/Final Features/Final_Features_{}-{}.pkl'.format(\n",
    "    star_ID,\n",
    "    fin_ID - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 911,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bin_start: 49000;Request: 49999; Row ID: 49999; Frequency: 1.668481306923984 requests/sec\n",
      "\n",
      "Run time: 311.73411297798157\n",
      "Average rate: 3.2078619514786055\n",
      "# of projects scraped: 1000\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "for i in range(40,len(bins)-1):\n",
    "#for i in range(0,4):   \n",
    "    \n",
    "    time_on = time.time()\n",
    "    \n",
    "    request_count = 0\n",
    "\n",
    "    star_ID = bins[i]\n",
    "    fin_ID = bins[i+1]\n",
    "\n",
    "    scraped = joblib.load('/Users/natacha/Documents/Insight/Scraped_HTML/scraped_html_{}-{}.pkl'.format(\n",
    "            star_ID,\n",
    "            fin_ID - 1))\n",
    "\n",
    "\n",
    "    new_features=[\"index1\",\"num_videos\",\"num_pics\",\"num_perks\",\"num_links\",\n",
    "              \"num_of_sent_about\",\"num_of_sent_risk\",\"num_of_sent_perks\",\n",
    "             \"num_of_words_about\",\"num_of_words_risk\",\"num_of_words_perks\",              \n",
    "             \"freq_bold_A\",\"freq_bold_R\",\n",
    "             \"freq_italic_A\",\"freq_italic_R\",\n",
    "             \"num_of_exclamation_A\",\"num_of_exclamation_R\",\"num_of_exclamation_P\",\n",
    "             \"bool_A\",\"bool_P\",\"bool_R\",\n",
    "             \"freq_pitch_A\",\"freq_pitch_R\",\"freq_pitch_P\"]\n",
    "    \n",
    "    \n",
    "    df_features=pd.DataFrame(columns=new_features)\n",
    "\n",
    "    \n",
    "    for index, row in scraped.iterrows():\n",
    "\n",
    "        par=get_parser(row[\"HTML\"])\n",
    "\n",
    "        text_about=get_text(par,\"about\")\n",
    "        text_risk=get_text(par,\"risk\")\n",
    "        text_perks=get_text(par,\"perks\")\n",
    "\n",
    "        bA=1\n",
    "        bR=1\n",
    "        bP=1\n",
    "        if text_about==\"NA\":\n",
    "            bA=0\n",
    "        if text_risk==\"NA\":\n",
    "            bR=0\n",
    "        if text_perks==\"NA\":\n",
    "            bP=0\n",
    "\n",
    "        features=(row[\"index1\"],num_of_videos(par,\"about\"),num_of_pics(par,\"about\"),num_of_perks(par),num_of_links(par,\"about\"),\n",
    "                  num_of_sentences(text_about), num_of_sentences(text_risk),num_of_sentences(text_perks),\n",
    "                  num_of_words(text_about),num_of_words(text_risk),num_of_words(text_perks),\n",
    "                  freq_of_bold(par,\"about\"),freq_of_bold(par,\"risk\"),\n",
    "                  freq_of_italic(par,\"about\"),freq_of_italic(par,\"risk\"),\n",
    "                  num_of_exclamation(par,\"about\"),num_of_exclamation(par,\"risk\"),num_of_exclamation(par,\"perks\"),\n",
    "                  bA,bP,bR,\n",
    "                  freq_of_pitchwords(par,\"about\"),freq_of_pitchwords(par,\"risk\"),freq_of_pitchwords(par,\"perks\")\n",
    "                  )\n",
    "\n",
    "        #print(features)\n",
    "        #print(features)\n",
    "        #elapsed_time = time.time() - time_on\n",
    "        #print(index, end=\" \")\n",
    "\n",
    "        df_features.loc[index]=features\n",
    "\n",
    "        elapsed_time = time.time() - time_on\n",
    "        clear_output(wait = True)\n",
    "        print(\n",
    "                'Bin_start: {};Request: {}; Row ID: {}; Frequency: {} requests/sec'.format(bins[i],\n",
    "                    request_count + star_ID,\n",
    "                    index,\n",
    "                    (request_count + 1) / elapsed_time\n",
    "                )\n",
    "            )\n",
    "        request_count += 1\n",
    "\n",
    "        \n",
    "\n",
    "    print()\n",
    "    print('Run time:', run_time)\n",
    "    print('Average rate:', len(scraped) / run_time)\n",
    "    print('# of projects scraped:', len(scraped))\n",
    "    \n",
    "    features_final=pd.concat([meta_sample[star_ID:fin_ID], df_features],axis=1,join_axes=[meta_sample[star_ID:fin_ID].index])\n",
    "\n",
    "    joblib.dump(\n",
    "    features_final, '/Users/natacha/Documents/Insight/Final Features/Final_Features_{}-{}.pkl'.format(\n",
    "        star_ID,\n",
    "        fin_ID - 1))\n",
    "        \n",
    "        \n",
    "print(\"DONE\")  \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "r=requests.get(\"https://www.kickstarter.com/projects/amplifierfoundation/we-the-future-art-for-the-classroom-and-beyond?ref=category_location&ref=discovery\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(r.text,\"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "mon=soup.find_all(\"span\",class_=\"ksr-green-700\")[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "248140"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(''.join(c for c in mon if c.isdigit()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [anaconda]",
   "language": "python",
   "name": "Python [anaconda]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
